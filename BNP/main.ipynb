{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot-end encoding for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CategoricalFeatureEncoder():\n",
    "    \n",
    "    def __init__(self, cat_features):\n",
    "        \n",
    "        self.cat_features = cat_features\n",
    "        self.features = {}\n",
    "        self.features_num = {}\n",
    "     \n",
    "   \n",
    "    def fit_transform(self, X_fit):\n",
    "        self.fit(X_fit)\n",
    "        return self.transform(X_fit)\n",
    "    \n",
    "    def fit(self, X_fit):\n",
    "        \n",
    "        for feature_name in self.cat_features:\n",
    "            col = X_fit.loc[:,feature_name]\n",
    "            self.fit_column(col)\n",
    "        \n",
    "                \n",
    "    def transform(self, X_transform):\n",
    "        for feature_name in self.cat_features:\n",
    "        \n",
    "            col = X_transform.loc[:,feature_name] \n",
    "            OHC_column = self.transform_column(col)\n",
    "\n",
    "            #create new names\n",
    "            col_names = []\n",
    "            for i in xrange(self.features_num[feature_name]):\n",
    "                col_names.append(feature_name + '__' + str(i))\n",
    "\n",
    "                \n",
    "                \n",
    "            OCH_pd = pd.DataFrame(OHC_column, columns=col_names)\n",
    "            X_transform = pd.concat([X_transform, OCH_pd], axis=1).drop(feature_name, axis=1)\n",
    "            \n",
    "            \n",
    "        return X_transform\n",
    "        \n",
    "        \n",
    "    def fit_column(self, col):\n",
    "        \n",
    "        col_name = col.name\n",
    "        col = col.dropna()\n",
    "        col = np.array(col)\n",
    "        \n",
    "        self.features[col_name] = {k: v for v, k in enumerate(list(np.unique(col)))}    \n",
    "        self.features_num[col_name] = len(self.features[col_name])\n",
    "    \n",
    "    def transform_column(self, col):\n",
    "        \n",
    "        col_name = col.name\n",
    "        col = np.array(col)\n",
    "        OHC_column = np.zeros((col.shape[0], self.features_num[col_name]))\n",
    "\n",
    "        for i in xrange(col.shape[0]):\n",
    "            if col[i] in self.features[col_name]:\n",
    "                \n",
    "                OHC_column[i, self.features[col_name][col[i]]] = 1\n",
    "        \n",
    "        return OHC_column\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## v22 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cat_feature:\n",
    "\n",
    "    def __init__(self, n_folds=3, alpha=1):\n",
    "         \n",
    "        self.n_folds = n_folds\n",
    "        self.alpha = alpha       \n",
    "\n",
    "        self.features_dict = {}\n",
    "\n",
    "    def fit_fold(self, col):\n",
    "        \n",
    "        for i in xrange(col.shape[0]):\n",
    "            pass\n",
    "        \n",
    "    def fit_transform(self, data, target, feature):\n",
    "        \n",
    "        self.current_feature = feature\n",
    "        self.globmean = target.mean()\n",
    "        \n",
    "        #create new feature\n",
    "        new_feature = feature + '__m'\n",
    "        \n",
    "        data[new_feature] = 0\n",
    "        kf = KFold(n_splits=self.n_folds)\n",
    "        \n",
    "        new_feature_column = np.zeros(data.shape[0])\n",
    "        \n",
    "        for ind1, ind2 in kf.split(data):\n",
    "            \n",
    "            # find smoothed mean for every feature value in ind1\n",
    "            \n",
    "            # create value - targets dict in current fold\n",
    "            \n",
    "            fold_dict = {}\n",
    "            for i in ind1:\n",
    "               \n",
    "                if data[feature][i] in fold_dict:\n",
    "                    fold_dict[data[feature][i]].append(target[i])\n",
    "                    \n",
    "                else:\n",
    "                    fold_dict[data[feature][i]] = [target[i]]\n",
    "        \n",
    "            # convert fold dict\n",
    "            for i in fold_dict:\n",
    "                \n",
    "                K = len(fold_dict[i])\n",
    "                meanY = np.mean(fold_dict[i])\n",
    "                fold_dict[i] =  (meanY * K + self.globmean * self.alpha) / (K + self.alpha)\n",
    "                \n",
    "            fold_dict[np.nan] = target.mean()\n",
    "            \n",
    "            # create new feature for every feature value in ind2        \n",
    "            for i in ind2:\n",
    "            \n",
    "                if data[feature][i] in fold_dict:\n",
    "                    new_feature_column[i] = fold_dict[data[feature][i]]\n",
    "                \n",
    "                else:\n",
    "                    new_feature_column[i] = fold_dict[np.nan]\n",
    "                    \n",
    "        # add new feature\n",
    "        data[new_feature] = new_feature_column\n",
    "        \n",
    "        #create dict from all data to use in transform()\n",
    "        \n",
    "        feature_dict = {}\n",
    "        for i in xrange(data.shape[0]):\n",
    "            \n",
    "            if data[feature][i] in feature_dict:\n",
    "                feature_dict[data[feature][i]].append(target[i])\n",
    "                    \n",
    "            else:\n",
    "                feature_dict[data[feature][i]] = [target[i]]\n",
    "                \n",
    "        \n",
    "        for i in feature_dict:\n",
    "                \n",
    "                K = len(feature_dict[i])\n",
    "                meanY = np.mean(feature_dict[i])\n",
    "                feature_dict[i] =  (meanY * K + self.globmean * self.alpha) / (K + self.alpha)\n",
    "                \n",
    "                \n",
    "        feature_dict[np.nan] = target.mean()\n",
    "        self.features_dict[feature] = feature_dict\n",
    "        \n",
    "    def transform(self, data, feature):\n",
    "        \n",
    "        new_feature = feature + '__m'\n",
    "        new_feature_column = np.zeros(data.shape[0])\n",
    "        data[new_feature] = 0\n",
    "        \n",
    "        for i in xrange(data.shape[0]):\n",
    "            \n",
    "            if data[feature][i] in self.features_dict[feature]:\n",
    "                new_feature_column[i] = self.features_dict[feature][data[feature][i]]\n",
    "                \n",
    "            else:\n",
    "                new_feature_column[i] = self.features_dict[feature][np.nan]\n",
    "                \n",
    "        data[new_feature] = new_feature_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/train.csv')\n",
    "data_test = pd.read_csv('data/test.csv')\n",
    "\n",
    "y_data_train = data_train.loc[:,'target'].values\n",
    "\n",
    "#train\n",
    "data_train = data_train.drop(['target', 'ID'], axis=1)\n",
    "data_train = data_train.fillna(data_train.median())\n",
    "#data_train = data_train.fillna('NaaN')\n",
    "\n",
    "#test \n",
    "subm_id = data_test.ID\n",
    "data_test = data_test.drop(['ID'], axis=1)\n",
    "data_test = data_test.fillna(data_test.median())\n",
    "#data_test = data_test.fillna('NaaN')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_features = ['v3', 'v24', 'v30', 'v31', 'v38', 'v47', 'v52', 'v56', 'v62', 'v66', \n",
    "                'v71', 'v74', 'v75', 'v79', 'v91', 'v107', 'v110', 'v112', 'v113', 'v125', 'v129']\n",
    "\n",
    "fe = CategoricalFeatureEncoder(cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_, X_test_, y_train, y_test = train_test_split(data_train, y_data_train, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "X_train_ = X_train_.reset_index(drop=True)\n",
    "X_test_ = X_test_.reset_index(drop=True)\n",
    "\n",
    "X_train_ = fe.fit_transform(X_train_)\n",
    "X_test_ = fe.transform(X_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Новый признак из v22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 40.2 ms, total: 15.2 s\n",
      "Wall time: 15.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CF = cat_feature(n_folds=4, alpha=10)\n",
    "CF.fit_transform(X_train_, y_train, 'v22')\n",
    "CF.transform(X_test_, 'v22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_.drop(['v22'], axis=1)\n",
    "X_test = X_test_.drop(['v22'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_.drop(['v22__m', 'v22'], axis=1)\n",
    "X_test = X_test_.drop(['v22__m', 'v22'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clf_xgb = xgb.XGBClassifier(n_estimators=1000, n_jobs=8, silent=False, max_depth=5, random_state=1, learning_rate=0.01)\n",
    "\n",
    "clf_xgb.fit(X_train, y_train)\n",
    "print 'fit done'\n",
    "\n",
    "p_xgb_pred = clf_xgb.predict_proba(X_test)[:,1]\n",
    "y_xgb_pred = clf_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'acc = ', accuracy_score(y_test, y_xgb_pred)\n",
    "print 'log_loss = ', log_loss(y_test, p_xgb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.45818499749 с 22\n",
    "0.459473795842 без"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fit done\n",
      "CPU times: user 1min 23s, sys: 468 ms, total: 1min 24s\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_log = LogisticRegression(C=1)\n",
    "\n",
    "clf_log.fit(X_train, y_train)\n",
    "print 'fit done'\n",
    "p_log_pred = clf_log.predict_proba(X_test)[:,1]\n",
    "\n",
    "y_log_pred = clf_log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc =  0.778360885157\n",
      "log_loss =  0.473968284769\n"
     ]
    }
   ],
   "source": [
    "print 'acc = ', accuracy_score(y_test, y_log_pred)\n",
    "print 'log_loss = ', log_loss(y_test, p_log_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subm = fe.transform(data_test)\n",
    "CF.transform(X_subm, 'v22')\n",
    "X_subm = X_subm.drop('v22', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_subm = clf_xgb.predict_proba(X_subm)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PredictedProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  PredictedProb\n",
       "0   0            0.5\n",
       "1   1            0.5\n",
       "2   2            0.5\n",
       "3   7            0.5\n",
       "4  10            0.5"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SS = pd.read_csv('data/sample_submission.csv')\n",
    "SS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30995306,  0.90285206,  0.87846667, ...,  0.86420178,\n",
       "        0.88268155,  0.49221018], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM = pd.DataFrame(columns=['ID', 'PredictedProb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM.ID = subm_id\n",
    "SUBM.PredictedProb = p_subm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>PredictedProb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.309953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.902852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.878467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.602573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.748438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  PredictedProb\n",
       "0   0       0.309953\n",
       "1   1       0.902852\n",
       "2   2       0.878467\n",
       "3   7       0.602573\n",
       "4  10       0.748438"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUBM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBM.to_csv('data/subm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
